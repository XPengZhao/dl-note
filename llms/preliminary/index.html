
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../neural-graphics/">
      
      
        <link rel="next" href="../models/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Preliminary - DL Notes</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/bootstrap.min.css">
    
      <link rel="stylesheet" href="../../stylesheets/basic.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#ai-infra-preliminary" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="DL Notes" class="md-header__button md-logo" aria-label="DL Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            DL Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Preliminary
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="DL Notes" class="md-nav__button md-logo" aria-label="DL Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    DL Notes
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Hardware
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tensor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tensor Operation
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../neural-graphics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Neural Graphics
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    LLMs
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    LLMs
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Preliminary
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Preliminary
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        Metrics
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#latency" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latency
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latency">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#time-to-first-token-ttft" class="md-nav__link">
    <span class="md-ellipsis">
      
        Time to first token (TTFT)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-per-output-token-tpot" class="md-nav__link">
    <span class="md-ellipsis">
      
        Time per output token (TPOT)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#throughput" class="md-nav__link">
    <span class="md-ellipsis">
      
        Throughput
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Throughput">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tokens-per-second-tps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tokens per Second (TPS)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        KV Cache
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="KV Cache">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#memory-cost" class="md-nav__link">
    <span class="md-ellipsis">
      
        Memory cost
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        Attention
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Attention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mha-multi-head-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        MHA — Multi-Head Attention
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mqa-multi-query-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        MQA — Multi-Query Attention
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gqa-grouped-query-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        GQA — Grouped-Query Attention
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sampling
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Sampling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#temperature" class="md-nav__link">
    <span class="md-ellipsis">
      
        Temperature
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#top-k-sampling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Top-k Sampling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#top-p-nucleus-sampling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Top-p (nucleus) Sampling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#min-p" class="md-nav__link">
    <span class="md-ellipsis">
      
        Min-p
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#put-them-together" class="md-nav__link">
    <span class="md-ellipsis">
      
        Put them together
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-code" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example code
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speculvative-decoding" class="md-nav__link">
    <span class="md-ellipsis">
      
        Speculvative decoding
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Speculvative decoding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rejection-sampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        Rejection Sampler
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pre-training-objective-of-llms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pre-training Objective of LLMs
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        Metrics
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#latency" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latency
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latency">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#time-to-first-token-ttft" class="md-nav__link">
    <span class="md-ellipsis">
      
        Time to first token (TTFT)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-per-output-token-tpot" class="md-nav__link">
    <span class="md-ellipsis">
      
        Time per output token (TPOT)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#throughput" class="md-nav__link">
    <span class="md-ellipsis">
      
        Throughput
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Throughput">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tokens-per-second-tps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tokens per Second (TPS)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        KV Cache
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="KV Cache">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#memory-cost" class="md-nav__link">
    <span class="md-ellipsis">
      
        Memory cost
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        Attention
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Attention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mha-multi-head-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        MHA — Multi-Head Attention
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mqa-multi-query-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        MQA — Multi-Query Attention
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gqa-grouped-query-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        GQA — Grouped-Query Attention
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sampling
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Sampling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#temperature" class="md-nav__link">
    <span class="md-ellipsis">
      
        Temperature
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#top-k-sampling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Top-k Sampling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#top-p-nucleus-sampling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Top-p (nucleus) Sampling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#min-p" class="md-nav__link">
    <span class="md-ellipsis">
      
        Min-p
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#put-them-together" class="md-nav__link">
    <span class="md-ellipsis">
      
        Put them together
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-code" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example code
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speculvative-decoding" class="md-nav__link">
    <span class="md-ellipsis">
      
        Speculvative decoding
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Speculvative decoding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rejection-sampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        Rejection Sampler
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pre-training-objective-of-llms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pre-training Objective of LLMs
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="ai-infra-preliminary">AI Infra Preliminary</h1>
<h2 id="metrics">Metrics</h2>
<h3 id="latency">Latency</h3>
<p>Latency is the time taken to process a request and generate output tokens. In LLM inference, latency is often measured in two main metrics:</p>
<h4 id="time-to-first-token-ttft">Time to first token (TTFT)</h4>
<p>Time to First Token (TTFT) is the latency between when a request is received by the inference server and when the first output token is generated and returned to the client. It measures how quickly the model begins responding, and is a primary user-perceived latency metric in streaming LLM systems. Formally:</p>
<div class="arithmatex">\[
\text{TTFT} = t_{\text{first token emitted}} - t_{\text{request received}}
\]</div>
<p>TTFT mainly captures the prefill phase (processing the input context) plus scheduling and system overhead. It does not include the time required to generate the rest of the output tokens. In details TTFT can be decomposed into:</p>
<div class="arithmatex">\[
\small
\begin{aligned}
\text{TTFT} = t_{\text{queue}} + t_{\text{input processing}} + t_{\text{prefill compute}} + t_{\text{first decode step (optional)}} + t_{\text{framework overhead}}
\end{aligned}
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(t_{\text{queue}}\)</span> is the time spent waiting in the scheduler before the request is admitted for execution.</li>
<li><span class="arithmatex">\(t_{\text{input processing}}\)</span> includes tokenization, multimodal preprocessing (e.g., image or video encoding), and any request-level normalization or formatting.</li>
<li><span class="arithmatex">\(t_{\text{prefill compute}}\)</span> is the time required to run the forward pass over all input tokens (complexity is <span class="arithmatex">\(O(L)\)</span> in sequence length <span class="arithmatex">\(L\)</span>), during which the KV cache is populated and the logits at the final prompt position are produced.</li>
<li><span class="arithmatex">\(t_{\text{first decode step (optional)}}\)</span> accounts for an additional single-step decode iteration in implementations that separate prefill and generation scheduling. In such systems, the first output token is emitted during a subsequent decode pass rather than directly from the prefill logits. In optimized implementations (recent versions of vLLM), this step may be fused with prefill and therefore negligible.</li>
<li><span class="arithmatex">\(t_{\text{framework overhead}}\)</span> captures auxiliary costs such as CUDA kernel launches, synchronization, memory allocation, sampling (softmax and top-k/top-p), and network transmission of the first streamed token.</li>
</ul>
<p>For long-context inputs, TTFT is typically dominated by <span class="arithmatex">\(t_{\text{prefill compute}}\)</span>, with the remaining terms contributing comparatively small overhead.</p>
<h4 id="time-per-output-token-tpot">Time per output token (TPOT)</h4>
<p>Time per Output Token (TPOT) measures the average latency required to generate each token after the first token has been emitted. It characterizes the steady-state decode performance of an autoregressive model and directly determines streaming speed. Formally, for a request generating <span class="arithmatex">\(N\)</span> output tokens:</p>
<div class="arithmatex">\[
\text{TPOT} = \frac{t_\text{last token emitted} - t_\text{first token emitted}}{N - 1}
\]</div>
<p>Equivalently, if total end-to-end latency is <span class="arithmatex">\(T_{\text{total}}\)</span>,</p>
<div class="arithmatex">\[
\text{TPOT} = \frac{T_{\text{total}} - \text{TTFT}}{N - 1}
\]</div>
<p>In steady-state decoding, each output token requires:</p>
<div class="arithmatex">\[
\text{TPOT} = t_{\text{decode compute}} + t_{\text{communication}} + t_{\text{scheduling}} + t_{\text{framework overhead}}
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(t_{\text{decode compute}}\)</span> is the forward pass for a single token using the KV cache (complexity per step is <span class="arithmatex">\(O(1+\text{num speculative tokens})\)</span> in sequence length but proportional to model size).</li>
<li><span class="arithmatex">\(t_{\text{communication}}\)</span> captures the cost of cross-GPU synchronization and data exchange, such as tensor-parallel collectives (all-reduce, all-gather), expert routing and aggregation in MoE models (all-to-all, dispatch/combine), as well as any host–device memory transfers (H2D/D2H) triggered by scheduling or memory management.</li>
<li><span class="arithmatex">\(t_{\text{scheduling}}\)</span> includes runtime scheduling overhead such as continuous batching, request coordination, admission control, and KV cache allocation, paging, or memory management.</li>
<li><span class="arithmatex">\(t_{\text{framework overhead}}\)</span> includes auxiliary execution costs such as sampling (softmax, top-k/top-p), kernel launches, synchronization, input/output marshaling, post-processing of results, and token streaming.</li>
</ul>
<p>Unlike TTFT, TPOT does not require recomputation over the full prompt. However, it still depends on the effective context length, since each decode step performs attention over all cached tokens. Therefore, TPOT scales approximately linearly with the total context length (prompt + generated tokens), though the per-token cost is significantly smaller than prefill.</p>
<h3 id="throughput">Throughput</h3>
<h4 id="tokens-per-second-tps">Tokens per Second (TPS)</h4>
<p>Tokens per Second (TPS) measures the throughput of an LLM inference system, i.e., how many tokens are processed or generated per second under a given serving configuration. Unlike TTFT and TPOT, which are latency metrics defined at the request level, TPS is a system-level metric that reflects overall serving capacity under load. Over a time interval over a time interval <span class="arithmatex">\(\Delta t\)</span>, TPS can be expressed as:</p>
<div class="arithmatex">\[
\text{TPS} = \frac{N_\text{tokens}}{\Delta t}
\]</div>
<p>In many cases, TPS refers specifically to decode throughput, counting only generated output tokens:</p>
<div class="arithmatex">\[
\text{TPS}_\text{decode} = \frac{N_\text{output tokens}}{\Delta t}
\]</div>
<p>and for a single sequence decoded sequentially, it is approximately the inverse of TPOT:</p>
<div class="arithmatex">\[
\text{TPS}_\text{per request} \approx \frac{1}{\text{TPOT}}
\]</div>
<p>However, in practical serving systems with continuous batching and concurrent decoding, aggregate throughput scales with the effective batch size <span class="arithmatex">\(B\)</span>. For a single replica, the system throughput can be approximated as</p>
<div class="arithmatex">\[
\text{TPS}_\text{replica} \approx \frac{B}{\text{TPOT}}
\]</div>
<p>and with <span class="arithmatex">\(R\)</span> data-parallel (DP) replicas,</p>
<div class="arithmatex">\[
\text{TPS}_\text{total} \approx R \times \frac{B}{\text{TPOT}}
\]</div>
<p>Importantly, for long-context or multimodal workloads, prompt processing can contribute a substantial fraction of total computation. In such cases, it is often necessary to consider end-to-end throughput, which accounts for both prompt and generated tokens:</p>
<div class="arithmatex">\[
\text{TPS}_\text{end-to-end} = \frac{N_\text{prompt tokens} + N_\text{output tokens}}{\Delta t}
\]</div>
<p>Overall, TPS is influenced by model size, parallelism strategy, effective batch size, kernel efficiency, interconnect bandwidth, and the relative balance between prefill and decode workloads.</p>
<h2 id="kv-cache">KV Cache</h2>
<h3 id="memory-cost">Memory cost</h3>
<p>The KV cache size is calculated as:</p>
<div class="arithmatex">\[
\text{KV size} = 2 \times \text{num layers} \times \text{num heads} \times \text{seq len} \times \text{head dim}
\]</div>
<p>Assume:</p>
<ul>
<li>32 layers, 80 heads, head_dim = 128, seq_len = 4K.</li>
<li>FP16 KV cache: 2 × 32 × 80 × 4K × 128 × 2 bytes = <strong>~5.2 GB</strong> per sample.</li>
<li>C8 (int8 KV cache): <strong>half that → ~2.6 GB</strong> per sample.</li>
</ul>
<h2 id="attention">Attention</h2>
<p>In transformer models, the attention module computes:</p>
<div class="arithmatex">\[
\operatorname{Attention}(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^T}{\sqrt{d_k}}\right) V
\]</div>
<p>Every token produces:</p>
<ul>
<li><strong>Q (Query)</strong> — derived from the current token’s hidden state</li>
<li><strong>K (Key)</strong>, <strong>V (Value)</strong> — derived from the context (previous tokens) and stored in the <strong>KV cache</strong></li>
</ul>
<p>The difference between <strong>MHA</strong>, <strong>MQA</strong>, and <strong>GQA</strong> lies in <strong>how many Key/Value projections</strong> are used relative to the number of Query heads.</p>
<h3 id="mha-multi-head-attention"><strong>MHA — Multi-Head Attention</strong></h3>
<p>Each attention head has its own set of projections:</p>
<div class="arithmatex">\[
Q_i=X W_{Q, i}, \quad K_i=X W_{K, i}, \quad V_i=X W_{V, i}
\]</div>
<ul>
<li>Q heads = K heads = V heads</li>
</ul>
<h3 id="mqa-multi-query-attention"><strong>MQA — Multi-Query Attention</strong></h3>
<p>All heads <strong>share one</strong> K and V projection:</p>
<div class="arithmatex">\[
K_{\text {shared }}=X W_K, \quad V_{\text {shared }}=X W_V
\]</div>
<ul>
<li><strong>Multiple Q heads</strong>, but <strong>only one pair of shared K/V</strong>.</li>
<li>During inference, the same K/V are reused for all heads.</li>
<li>KV cache size reduced by ~#heads×</li>
<li><strong>LLaMA 2 7B</strong>, <strong>Mistral</strong>, and most optimized LLMs use MQA to cut memory usage.</li>
</ul>
<h3 id="gqa-grouped-query-attention"><strong>GQA — Grouped-Query Attention</strong></h3>
<p>Queries are split into groups, and each group shares its own K/V:</p>
<div class="arithmatex">\[
\text { Group } g: \quad Q_{g, *}, K_g, V_g
\]</div>
<ul>
<li>Suppose you have 8 query heads but only 2 groups → 4 Q heads per group share one K/V.</li>
<li><strong>K/V heads &lt; Q heads</strong>.</li>
<li><strong>LLaMA 2 70B</strong>, <strong>Mixtral</strong>, <strong>GPT-J-6B</strong>, etc. use GQA for better memory efficiency.</li>
</ul>
<h2 id="sampling">Sampling</h2>
<h3 id="temperature">Temperature</h3>
<p>Temperature <span class="arithmatex">\(T\)</span> controls "sharpness" of the probability distribution. Given model logits <span class="arithmatex">\(z_i\)</span>, temperature sampling rescales them before softmax:</p>
<div class="arithmatex">\[
p_i=\frac{e^{z_i / T}}{\sum_j e^{z_j / T}}
\]</div>
<ul>
<li><span class="arithmatex">\(T&lt;1\)</span> Sharper (more peaked). Model becomes confident, less random. <span class="arithmatex">\(T&gt;1\)</span> Flatter (more uniform). Model becomes exploratory, more diverse.</li>
<li>Temperature keeps the order of logits because dividing by a positive number does not change ranking (rank-preserving). If you use top-k = 1 (i.e., greedy), temperature has no effect at all.</li>
<li>With a temperature <span class="arithmatex">\(T \rightarrow 0\)</span>, the softmax distribution becomes arbitrarily sharp and converges to greedy (argmax) sampling. For example, at <span class="arithmatex">\(T=10^{-6}\)</span>, the highest logit dominates the distribution, so sampling is effectively greedy in practice.</li>
<li>At <span class="arithmatex">\(T \rightarrow \infty\)</span>, the distribution becomes uniform (all tokens equally likely).</li>
</ul>
<h3 id="top-k-sampling">Top-k Sampling</h3>
<p>After computing probabilities (after temperature), sort tokens by probability, and keep only the k highest. Then renormalize <span class="arithmatex">\(p_i^{\prime}\)</span> to get final distribution for sampling.</p>
<div class="arithmatex">\[
\begin{aligned}
S_k &amp; =\text { top-k tokens by } p_i \\
p_i^{\prime} &amp; = \begin{cases}\frac{p_i}{\sum_{j \in S_k} p_j} &amp; i \in S_k \\
0 &amp; \text { otherwise }\end{cases}
\end{aligned}
\]</div>
<p>Then you sample from that truncated distribution.</p>
<ul>
<li>Small k (e.g., 1–10): deterministic and safe (model never picks rare words).</li>
<li>Large k (e.g., 50–100): more variety but higher risk of off-topic words.</li>
</ul>
<h3 id="top-p-nucleus-sampling">Top-p (nucleus) Sampling</h3>
<p>“nucleus” literally means core, center, or the essential central part of something. Instead of a fixed k, we choose the smallest set of tokens whose cumulative probability <span class="arithmatex">\(\geq p\)</span>.</p>
<div class="arithmatex">\[
\begin{aligned}
S_p&amp;=\left\{i: \sum_{j \in S_p} p_j \geq p\right\} \\
p_i^{\prime}&amp;= \begin{cases}\frac{p_i}{\sum_{j \in S_p} p_j} &amp; i \in S_p \\
0 &amp; \text { otherwise }\end{cases}
\end{aligned}
\]</div>
<p><strong>Key difference vs top-k:</strong></p>
<p>Top-p adapts to uncertainty. Top-k is about rank (k highest scores). Top-p is about mass (the core mass of the distribution).</p>
<ul>
<li>If the model is confident (one token dominates), very few tokens are kept.</li>
<li>If it’s uncertain (many tokens have similar probabilities), the nucleus expands.</li>
</ul>
<h3 id="min-p">Min-p</h3>
<p>Min-p filters out tokens that are too improbable relative to the top-1. This is newer but increasingly popular (used in Mistral, Gemini, etc.). Instead of fixing <span class="arithmatex">\(k\)</span> or <span class="arithmatex">\(p\)</span>, you keep tokens above a minimum probability threshold relative to the top-1 token:</p>
<div class="arithmatex">\[
S_{\min }=\left\{i: p_i \geq \min -\mathrm{p} \times p_{\max }\right\}
\]</div>
<p>If min-p = 0.1, then any token whose probability is at least 10% of the most likely token is kept.Then normalize:</p>
<div class="arithmatex">\[
p_i^{\prime} = \frac{p_i}{\sum_{j \in S_{\min}} p_j}
\]</div>
<ul>
<li>Min-p adaptive to context like top-p, but simpler. It means the number of candidate tokens changes depending on what the model is predicting. If the model is confident, the candidate set is small. If the model is uncertain, the candidate set becomes larger.</li>
<li>Avoids cutting off plausible low-rank tokens when the distribution is flat.</li>
<li>More numerically stable for long-tail vocabularies.</li>
</ul>
<h3 id="put-them-together">Put them together</h3>
<p>You usually combine these in a specific order: Temperature → Softmax → (top-k / top-p / min-p) → Renormalize → Sample</p>
<p>When both top-k and top-p are enabled, you always keep the intersection, which is the smaller of the two sets.</p>
<h3 id="example-code">Example code</h3>
<p>Code snippet from <a href="https://gitee.com/omniai/omniinfer/blob/master/omni/adaptors/vllm/sample/sampler.py">Omniinfer Sampler</a>.</p>
<details>
<summary>Top-k and Top-p implementation</summary>

<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">apply_top_k_top_p</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">logits_or_prob</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">p</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">is_logits</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="k">if</span> <span class="n">p</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>        <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>            <span class="n">logits_or_prob</span> <span class="o">=</span> <span class="n">apply_top_k_only</span><span class="p">(</span><span class="n">logits_or_prob</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">is_logits</span><span class="p">)</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>        <span class="k">if</span> <span class="n">is_logits</span><span class="p">:</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>            <span class="n">probs</span> <span class="o">=</span> <span class="n">logits_or_prob</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>            <span class="n">probs</span> <span class="o">=</span> <span class="n">logits_or_prob</span> <span class="o">/</span> <span class="n">logits_or_prob</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="k">return</span> <span class="n">probs</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">logits_or_prob_sort</span><span class="p">,</span> <span class="n">logits_or_prob_idx</span> <span class="o">=</span> <span class="n">logits_or_prob</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>        <span class="c1"># Apply top-k.</span>
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span class="n">top_k_mask</span> <span class="o">=</span> <span class="n">logits_or_prob_sort</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">k</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>  <span class="c1"># shape: B</span>
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>        <span class="c1"># Get all the top_k values.</span>
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>        <span class="n">top_k_mask</span> <span class="o">=</span> <span class="n">logits_or_prob_sort</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">top_k_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</span><span id="__span-0-23"><a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        <span class="n">top_k_mask</span> <span class="o">=</span> <span class="n">logits_or_prob_sort</span> <span class="o">&lt;</span> <span class="n">top_k_mask</span>
</span><span id="__span-0-24"><a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>        <span class="n">logits_or_prob_sort</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">top_k_mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_logits</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-25"><a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>
</span><span id="__span-0-26"><a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>    <span class="c1"># Apply top-p.</span>
</span><span id="__span-0-27"><a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>    <span class="k">if</span> <span class="n">is_logits</span><span class="p">:</span>
</span><span id="__span-0-28"><a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>        <span class="n">probs_sort</span> <span class="o">=</span> <span class="n">logits_or_prob_sort</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-29"><a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-30"><a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>        <span class="n">probs_sort</span> <span class="o">=</span> <span class="n">logits_or_prob_sort</span> <span class="o">/</span> <span class="n">logits_or_prob_sort</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-31"><a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>    <span class="n">probs_sum</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">probs_sort</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">probs_sort</span><span class="p">)</span>
</span><span id="__span-0-32"><a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>    <span class="n">top_p_mask</span> <span class="o">=</span> <span class="n">probs_sum</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-33"><a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>    <span class="c1"># at least one</span>
</span><span id="__span-0-34"><a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>    <span class="n">top_p_mask</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="__span-0-35"><a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>    <span class="n">probs_sort</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">top_p_mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-36"><a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>    <span class="n">probs</span> <span class="o">=</span> <span class="n">probs_sort</span> <span class="o">/</span> <span class="n">probs_sort</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-37"><a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>    <span class="k">return</span> <span class="n">probs</span><span class="p">,</span> <span class="n">logits_or_prob_idx</span>
</span></code></pre></div>

<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">apply_top_k_only</span><span class="p">(</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>    <span class="n">logits_or_prob</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>    <span class="n">k</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>    <span class="n">is_logits</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="sd">    Apply top-k mask to the logits.</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a><span class="sd">    This implementation doesn&#39;t involve sorting the entire vocab.</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a><span class="sd">    The logits tensor may be updated in-place.</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>    <span class="n">no_top_k_mask</span> <span class="o">=</span> <span class="n">k</span> <span class="o">==</span> <span class="n">logits_or_prob</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>    <span class="c1"># Set non-top-k rows to 1 so that we can gather.</span>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>    <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">no_top_k_mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>    <span class="n">max_top_k</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>    <span class="c1"># topk.values tensor has shape [batch_size, max_top_k].</span>
</span><span id="__span-1-18"><a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>    <span class="c1"># Convert top k to 0-based index in range [0, max_top_k).</span>
</span><span id="__span-1-19"><a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>    <span class="n">k_index</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-1-20"><a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>    <span class="n">top_k_mask</span> <span class="o">=</span> <span class="n">logits_or_prob</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">max_top_k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">k_index</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span id="__span-1-21"><a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a>    <span class="c1"># Handle non-topk rows.</span>
</span><span id="__span-1-22"><a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a>    <span class="n">top_k_mask</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">no_top_k_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">))</span>
</span><span id="__span-1-23"><a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a>    <span class="n">logits_or_prob</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">logits_or_prob</span> <span class="o">&lt;</span> <span class="n">top_k_mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_logits</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span><span id="__span-1-24"><a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a>    <span class="k">return</span> <span class="n">logits_or_prob</span>
</span></code></pre></div>
</details>

<h2 id="speculvative-decoding">Speculvative decoding</h2>
<h3 id="rejection-sampler">Rejection Sampler</h3>
<p>To sample <span class="arithmatex">\(x \sim p(x)\)</span>,  we instead sample <span class="arithmatex">\(x \sim q(x)\)</span>, keeping it if <span class="arithmatex">\(q(x) \leq p(x)\)</span>, and in case <span class="arithmatex">\(q(x) &gt; p(x)\)</span>, we reject the
sample with probability <span class="arithmatex">\(1 - \frac{p(x)}{q(x)}\)</span> and resample <span class="arithmatex">\(x\)</span>  from an adjusted distribution <span class="arithmatex">\(p^{\prime} = \text{norm}(\max(0, p(x) - q(x)))\)</span> instead.</p>
<p><strong>NOTE:</strong> For for any distributions <span class="arithmatex">\(p(x)\)</span> and <span class="arithmatex">\(q(x)\)</span>, the tokens sampled via rejection sampling from <span class="arithmatex">\(p(x)\)</span> and <span class="arithmatex">\(q(x)\)</span> are distributed identically to those sampled from <span class="arithmatex">\(p(x)\)</span> alone. The proof is in Appendix A [1].</p>
<p>Rejection sampling works by decomposing the target distribution <span class="arithmatex">\(p(x)\)</span> into two parts:</p>
<ul>
<li>The accept branch, where tokens are accepted based on the ratio <span class="arithmatex">\(\frac{p(x)}{q(x)}\)</span>, where <span class="arithmatex">\(q(x)\)</span> is the proposal (draft) distribution.</li>
</ul>
<div class="arithmatex">\[
  p(\text{accepted}, x = x^{\prime}) = q(x^{\prime}) \cdot \min\left(\frac{p(x^{\prime})}{q(x^{\prime})}, 1\right) = \min(p(x^{\prime}), q(x^{\prime}))
\]</div>
<ul>
<li>The reject branch, where tokens are rejected and resampled from the adjusted distribution <span class="arithmatex">\(p^{\prime}(x)\)</span>. The probability of all tokens being sampled from <span class="arithmatex">\(q(x)\)</span> being rejected as:</li>
</ul>
<div class="arithmatex">\[
\begin{aligned}
    p(\text{rejected}) &amp;= \sum_{x} q(x) \left(1 - \min\left(\frac{p(x)}{q(x)}, 1\right)\right) \\
    &amp;= \sum_{x} \max(0, q(x) - p(x)) \\
\end{aligned}
\]</div>
<div class="arithmatex">\[
\begin{aligned}
    p(\text{rejected}) &amp;= \sum_{x} q(x) \left(1 - \min\left(\frac{p(x)}{q(x)}, 1\right)\right) \\
    &amp;= \sum_{x} \max(0, q(x) - p(x)) \\
\end{aligned}
\]</div>
<p><strong>Example Code</strong></p>
<p>Code snippet from <a href="https://github.com/vllm-project/vllm/blob/main/vllm/v1/sample/rejection_sampler.py">vLLM</a>.</p>
<details>
<summary>Rejection sampling kernel in Triton</summary>

<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="c1"># NOTE(woosuk): Avoid specialization to prevent unnecessary recompilation.</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="nd">@triton</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">do_not_specialize</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;max_spec_len&quot;</span><span class="p">])</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="k">def</span><span class="w"> </span><span class="nf">rejection_random_sample_kernel</span><span class="p">(</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>    <span class="n">output_token_ids_ptr</span><span class="p">,</span>  <span class="c1"># [batch_size, max_spec_len + 1]</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>    <span class="n">cu_num_draft_tokens_ptr</span><span class="p">,</span>  <span class="c1"># [batch_size]</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>    <span class="n">draft_token_ids_ptr</span><span class="p">,</span>  <span class="c1"># [num_tokens]</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>    <span class="n">draft_probs_ptr</span><span class="p">,</span>  <span class="c1"># [num_tokens, vocab_size] or None</span>
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>    <span class="n">target_probs_ptr</span><span class="p">,</span>  <span class="c1"># [num_tokens, vocab_size]</span>
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>    <span class="n">bonus_token_ids_ptr</span><span class="p">,</span>  <span class="c1"># [batch_size]</span>
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>    <span class="n">recovered_token_ids_ptr</span><span class="p">,</span>  <span class="c1"># [num_tokens]</span>
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>    <span class="n">uniform_probs_ptr</span><span class="p">,</span>  <span class="c1"># [num_tokens]</span>
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>    <span class="n">is_greedy_ptr</span><span class="p">,</span>  <span class="c1"># [batch_size]</span>
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>    <span class="n">max_spec_len</span><span class="p">,</span>
</span><span id="__span-2-14"><a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>    <span class="n">vocab_size</span><span class="p">,</span>
</span><span id="__span-2-15"><a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>    <span class="n">NO_DRAFT_PROBS</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>
</span><span id="__span-2-16"><a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a><span class="p">):</span>
</span><span id="__span-2-17"><a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a>    <span class="n">req_idx</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-2-18"><a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a>    <span class="n">is_greedy</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">is_greedy_ptr</span> <span class="o">+</span> <span class="n">req_idx</span><span class="p">)</span>
</span><span id="__span-2-19"><a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a>    <span class="k">if</span> <span class="n">is_greedy</span><span class="p">:</span>
</span><span id="__span-2-20"><a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a>        <span class="c1"># Early exit for greedy sampling requests.</span>
</span><span id="__span-2-21"><a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a>        <span class="k">return</span>
</span><span id="__span-2-22"><a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a>
</span><span id="__span-2-23"><a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a>    <span class="n">start_idx</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">req_idx</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">cu_num_draft_tokens_ptr</span> <span class="o">+</span> <span class="n">req_idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-2-24"><a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a>    <span class="n">end_idx</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">cu_num_draft_tokens_ptr</span> <span class="o">+</span> <span class="n">req_idx</span><span class="p">)</span>
</span><span id="__span-2-25"><a id="__codelineno-2-25" name="__codelineno-2-25" href="#__codelineno-2-25"></a>    <span class="n">num_draft_tokens</span> <span class="o">=</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">start_idx</span>
</span><span id="__span-2-26"><a id="__codelineno-2-26" name="__codelineno-2-26" href="#__codelineno-2-26"></a>
</span><span id="__span-2-27"><a id="__codelineno-2-27" name="__codelineno-2-27" href="#__codelineno-2-27"></a>    <span class="n">rejected</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="__span-2-28"><a id="__codelineno-2-28" name="__codelineno-2-28" href="#__codelineno-2-28"></a>    <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_draft_tokens</span><span class="p">):</span>
</span><span id="__span-2-29"><a id="__codelineno-2-29" name="__codelineno-2-29" href="#__codelineno-2-29"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">rejected</span><span class="p">:</span>
</span><span id="__span-2-30"><a id="__codelineno-2-30" name="__codelineno-2-30" href="#__codelineno-2-30"></a>            <span class="n">draft_token_id</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">draft_token_ids_ptr</span> <span class="o">+</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">pos</span><span class="p">)</span>
</span><span id="__span-2-31"><a id="__codelineno-2-31" name="__codelineno-2-31" href="#__codelineno-2-31"></a>            <span class="k">if</span> <span class="n">NO_DRAFT_PROBS</span><span class="p">:</span>
</span><span id="__span-2-32"><a id="__codelineno-2-32" name="__codelineno-2-32" href="#__codelineno-2-32"></a>                <span class="n">draft_prob</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="__span-2-33"><a id="__codelineno-2-33" name="__codelineno-2-33" href="#__codelineno-2-33"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-2-34"><a id="__codelineno-2-34" name="__codelineno-2-34" href="#__codelineno-2-34"></a>                <span class="n">draft_prob</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
</span><span id="__span-2-35"><a id="__codelineno-2-35" name="__codelineno-2-35" href="#__codelineno-2-35"></a>                    <span class="n">draft_probs_ptr</span> <span class="o">+</span> <span class="p">(</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">pos</span><span class="p">)</span> <span class="o">*</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="n">draft_token_id</span>
</span><span id="__span-2-36"><a id="__codelineno-2-36" name="__codelineno-2-36" href="#__codelineno-2-36"></a>                <span class="p">)</span>
</span><span id="__span-2-37"><a id="__codelineno-2-37" name="__codelineno-2-37" href="#__codelineno-2-37"></a>            <span class="n">target_prob</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
</span><span id="__span-2-38"><a id="__codelineno-2-38" name="__codelineno-2-38" href="#__codelineno-2-38"></a>                <span class="n">target_probs_ptr</span> <span class="o">+</span> <span class="p">(</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">pos</span><span class="p">)</span> <span class="o">*</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="n">draft_token_id</span>
</span><span id="__span-2-39"><a id="__codelineno-2-39" name="__codelineno-2-39" href="#__codelineno-2-39"></a>            <span class="p">)</span>
</span><span id="__span-2-40"><a id="__codelineno-2-40" name="__codelineno-2-40" href="#__codelineno-2-40"></a>            <span class="n">uniform_prob</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">uniform_probs_ptr</span> <span class="o">+</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">pos</span><span class="p">)</span>
</span><span id="__span-2-41"><a id="__codelineno-2-41" name="__codelineno-2-41" href="#__codelineno-2-41"></a>            <span class="c1"># NOTE(woosuk): While the draft probability should never be 0,</span>
</span><span id="__span-2-42"><a id="__codelineno-2-42" name="__codelineno-2-42" href="#__codelineno-2-42"></a>            <span class="c1"># we check it to avoid NaNs. If it happens to be 0, we reject.</span>
</span><span id="__span-2-43"><a id="__codelineno-2-43" name="__codelineno-2-43" href="#__codelineno-2-43"></a>            <span class="k">if</span> <span class="n">draft_prob</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">target_prob</span> <span class="o">/</span> <span class="n">draft_prob</span> <span class="o">&gt;=</span> <span class="n">uniform_prob</span><span class="p">:</span>
</span><span id="__span-2-44"><a id="__codelineno-2-44" name="__codelineno-2-44" href="#__codelineno-2-44"></a>                <span class="c1"># Accept.</span>
</span><span id="__span-2-45"><a id="__codelineno-2-45" name="__codelineno-2-45" href="#__codelineno-2-45"></a>                <span class="n">token_id</span> <span class="o">=</span> <span class="n">draft_token_id</span>
</span><span id="__span-2-46"><a id="__codelineno-2-46" name="__codelineno-2-46" href="#__codelineno-2-46"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-2-47"><a id="__codelineno-2-47" name="__codelineno-2-47" href="#__codelineno-2-47"></a>                <span class="c1"># Reject. Use recovered token.</span>
</span><span id="__span-2-48"><a id="__codelineno-2-48" name="__codelineno-2-48" href="#__codelineno-2-48"></a>                <span class="n">rejected</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="__span-2-49"><a id="__codelineno-2-49" name="__codelineno-2-49" href="#__codelineno-2-49"></a>                <span class="n">token_id</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">recovered_token_ids_ptr</span> <span class="o">+</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">pos</span><span class="p">)</span>
</span><span id="__span-2-50"><a id="__codelineno-2-50" name="__codelineno-2-50" href="#__codelineno-2-50"></a>            <span class="n">tl</span><span class="o">.</span><span class="n">store</span><span class="p">(</span>
</span><span id="__span-2-51"><a id="__codelineno-2-51" name="__codelineno-2-51" href="#__codelineno-2-51"></a>                <span class="n">output_token_ids_ptr</span> <span class="o">+</span> <span class="n">req_idx</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_spec_len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">pos</span><span class="p">,</span> <span class="n">token_id</span>
</span><span id="__span-2-52"><a id="__codelineno-2-52" name="__codelineno-2-52" href="#__codelineno-2-52"></a>            <span class="p">)</span>
</span><span id="__span-2-53"><a id="__codelineno-2-53" name="__codelineno-2-53" href="#__codelineno-2-53"></a>
</span><span id="__span-2-54"><a id="__codelineno-2-54" name="__codelineno-2-54" href="#__codelineno-2-54"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">rejected</span><span class="p">:</span>
</span><span id="__span-2-55"><a id="__codelineno-2-55" name="__codelineno-2-55" href="#__codelineno-2-55"></a>        <span class="c1"># If all tokens are accepted, append the bonus token.</span>
</span><span id="__span-2-56"><a id="__codelineno-2-56" name="__codelineno-2-56" href="#__codelineno-2-56"></a>        <span class="n">bonus_token_id</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">bonus_token_ids_ptr</span> <span class="o">+</span> <span class="n">req_idx</span><span class="p">)</span>
</span><span id="__span-2-57"><a id="__codelineno-2-57" name="__codelineno-2-57" href="#__codelineno-2-57"></a>        <span class="n">tl</span><span class="o">.</span><span class="n">store</span><span class="p">(</span>
</span><span id="__span-2-58"><a id="__codelineno-2-58" name="__codelineno-2-58" href="#__codelineno-2-58"></a>            <span class="n">output_token_ids_ptr</span> <span class="o">+</span> <span class="n">req_idx</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_spec_len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">num_draft_tokens</span><span class="p">,</span>
</span><span id="__span-2-59"><a id="__codelineno-2-59" name="__codelineno-2-59" href="#__codelineno-2-59"></a>            <span class="n">bonus_token_id</span><span class="p">,</span>
</span><span id="__span-2-60"><a id="__codelineno-2-60" name="__codelineno-2-60" href="#__codelineno-2-60"></a>        <span class="p">)</span>
</span></code></pre></div>

</details>

<details>
<summary>Resample kernel in Triton</summary>


<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="nd">@triton</span><span class="o">.</span><span class="n">jit</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="k">def</span><span class="w"> </span><span class="nf">sample_recovered_tokens_kernel</span><span class="p">(</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>    <span class="n">output_token_ids_ptr</span><span class="p">,</span>  <span class="c1"># [num_tokens]</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>    <span class="n">cu_num_draft_tokens_ptr</span><span class="p">,</span>  <span class="c1"># [batch_size]</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>    <span class="n">draft_token_ids_ptr</span><span class="p">,</span>  <span class="c1"># [num_tokens]</span>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>    <span class="n">draft_probs_ptr</span><span class="p">,</span>  <span class="c1"># [num_tokens, vocab_size] or None</span>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>    <span class="n">target_probs_ptr</span><span class="p">,</span>  <span class="c1"># [num_tokens, vocab_size]</span>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>    <span class="n">q_ptr</span><span class="p">,</span>  <span class="c1"># [batch_size, vocab_size]</span>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>    <span class="n">vocab_size</span><span class="p">,</span>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>    <span class="n">PADDED_VOCAB_SIZE</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>    <span class="n">NO_DRAFT_PROBS</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a><span class="p">):</span>
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>    <span class="n">req_idx</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>    <span class="n">start_idx</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">req_idx</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">cu_num_draft_tokens_ptr</span> <span class="o">+</span> <span class="n">req_idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>    <span class="n">end_idx</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">cu_num_draft_tokens_ptr</span> <span class="o">+</span> <span class="n">req_idx</span><span class="p">)</span>
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>    <span class="n">num_draft_tokens</span> <span class="o">=</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">start_idx</span>
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>
</span><span id="__span-3-18"><a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>    <span class="c1"># Early exit for out-of-range positions.</span>
</span><span id="__span-3-19"><a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>    <span class="n">pos</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-3-20"><a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a>    <span class="k">if</span> <span class="n">pos</span> <span class="o">&gt;=</span> <span class="n">num_draft_tokens</span><span class="p">:</span>
</span><span id="__span-3-21"><a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>        <span class="k">return</span>
</span><span id="__span-3-22"><a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a>
</span><span id="__span-3-23"><a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a>    <span class="n">vocab_offset</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">PADDED_VOCAB_SIZE</span><span class="p">)</span>
</span><span id="__span-3-24"><a id="__codelineno-3-24" name="__codelineno-3-24" href="#__codelineno-3-24"></a>    <span class="k">if</span> <span class="n">NO_DRAFT_PROBS</span><span class="p">:</span>
</span><span id="__span-3-25"><a id="__codelineno-3-25" name="__codelineno-3-25" href="#__codelineno-3-25"></a>        <span class="n">draft_token_id</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">draft_token_ids_ptr</span> <span class="o">+</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">pos</span><span class="p">)</span>
</span><span id="__span-3-26"><a id="__codelineno-3-26" name="__codelineno-3-26" href="#__codelineno-3-26"></a>        <span class="n">prob</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
</span><span id="__span-3-27"><a id="__codelineno-3-27" name="__codelineno-3-27" href="#__codelineno-3-27"></a>            <span class="n">target_probs_ptr</span> <span class="o">+</span> <span class="p">(</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">pos</span><span class="p">)</span> <span class="o">*</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="n">vocab_offset</span><span class="p">,</span>
</span><span id="__span-3-28"><a id="__codelineno-3-28" name="__codelineno-3-28" href="#__codelineno-3-28"></a>            <span class="n">mask</span><span class="o">=</span><span class="p">((</span><span class="n">vocab_offset</span> <span class="o">&lt;</span> <span class="n">vocab_size</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">vocab_offset</span> <span class="o">!=</span> <span class="n">draft_token_id</span><span class="p">)),</span>
</span><span id="__span-3-29"><a id="__codelineno-3-29" name="__codelineno-3-29" href="#__codelineno-3-29"></a>            <span class="n">other</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-3-30"><a id="__codelineno-3-30" name="__codelineno-3-30" href="#__codelineno-3-30"></a>        <span class="p">)</span>
</span><span id="__span-3-31"><a id="__codelineno-3-31" name="__codelineno-3-31" href="#__codelineno-3-31"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-3-32"><a id="__codelineno-3-32" name="__codelineno-3-32" href="#__codelineno-3-32"></a>        <span class="n">draft_prob</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
</span><span id="__span-3-33"><a id="__codelineno-3-33" name="__codelineno-3-33" href="#__codelineno-3-33"></a>            <span class="n">draft_probs_ptr</span> <span class="o">+</span> <span class="p">(</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">pos</span><span class="p">)</span> <span class="o">*</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="n">vocab_offset</span><span class="p">,</span>
</span><span id="__span-3-34"><a id="__codelineno-3-34" name="__codelineno-3-34" href="#__codelineno-3-34"></a>            <span class="n">mask</span><span class="o">=</span><span class="n">vocab_offset</span> <span class="o">&lt;</span> <span class="n">vocab_size</span><span class="p">,</span>
</span><span id="__span-3-35"><a id="__codelineno-3-35" name="__codelineno-3-35" href="#__codelineno-3-35"></a>            <span class="n">other</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-3-36"><a id="__codelineno-3-36" name="__codelineno-3-36" href="#__codelineno-3-36"></a>        <span class="p">)</span>
</span><span id="__span-3-37"><a id="__codelineno-3-37" name="__codelineno-3-37" href="#__codelineno-3-37"></a>        <span class="n">target_prob</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
</span><span id="__span-3-38"><a id="__codelineno-3-38" name="__codelineno-3-38" href="#__codelineno-3-38"></a>            <span class="n">target_probs_ptr</span> <span class="o">+</span> <span class="p">(</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">pos</span><span class="p">)</span> <span class="o">*</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="n">vocab_offset</span><span class="p">,</span>
</span><span id="__span-3-39"><a id="__codelineno-3-39" name="__codelineno-3-39" href="#__codelineno-3-39"></a>            <span class="n">mask</span><span class="o">=</span><span class="n">vocab_offset</span> <span class="o">&lt;</span> <span class="n">vocab_size</span><span class="p">,</span>
</span><span id="__span-3-40"><a id="__codelineno-3-40" name="__codelineno-3-40" href="#__codelineno-3-40"></a>            <span class="n">other</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-3-41"><a id="__codelineno-3-41" name="__codelineno-3-41" href="#__codelineno-3-41"></a>        <span class="p">)</span>
</span><span id="__span-3-42"><a id="__codelineno-3-42" name="__codelineno-3-42" href="#__codelineno-3-42"></a>        <span class="n">prob</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">target_prob</span> <span class="o">-</span> <span class="n">draft_prob</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="__span-3-43"><a id="__codelineno-3-43" name="__codelineno-3-43" href="#__codelineno-3-43"></a>        <span class="c1"># NOTE(woosuk): We don&#39;t need `prob = prob / tl.sum(prob)` here because</span>
</span><span id="__span-3-44"><a id="__codelineno-3-44" name="__codelineno-3-44" href="#__codelineno-3-44"></a>        <span class="c1"># `tl.argmax` will select the maximum value.</span>
</span><span id="__span-3-45"><a id="__codelineno-3-45" name="__codelineno-3-45" href="#__codelineno-3-45"></a>
</span><span id="__span-3-46"><a id="__codelineno-3-46" name="__codelineno-3-46" href="#__codelineno-3-46"></a>    <span class="n">q</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
</span><span id="__span-3-47"><a id="__codelineno-3-47" name="__codelineno-3-47" href="#__codelineno-3-47"></a>        <span class="n">q_ptr</span> <span class="o">+</span> <span class="n">req_idx</span> <span class="o">*</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="n">vocab_offset</span><span class="p">,</span>
</span><span id="__span-3-48"><a id="__codelineno-3-48" name="__codelineno-3-48" href="#__codelineno-3-48"></a>        <span class="n">mask</span><span class="o">=</span><span class="n">vocab_offset</span> <span class="o">&lt;</span> <span class="n">vocab_size</span><span class="p">,</span>
</span><span id="__span-3-49"><a id="__codelineno-3-49" name="__codelineno-3-49" href="#__codelineno-3-49"></a>        <span class="n">other</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">),</span>
</span><span id="__span-3-50"><a id="__codelineno-3-50" name="__codelineno-3-50" href="#__codelineno-3-50"></a>    <span class="p">)</span>
</span><span id="__span-3-51"><a id="__codelineno-3-51" name="__codelineno-3-51" href="#__codelineno-3-51"></a>    <span class="n">recovered_id</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prob</span> <span class="o">/</span> <span class="n">q</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-3-52"><a id="__codelineno-3-52" name="__codelineno-3-52" href="#__codelineno-3-52"></a>    <span class="n">tl</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="n">output_token_ids_ptr</span> <span class="o">+</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">pos</span><span class="p">,</span> <span class="n">recovered_id</span><span class="p">)</span>
</span></code></pre></div>
</details>

<p><strong>Reference</strong></p>
<p><a href="https://arxiv.org/pdf/2211.17192">[1]</a> Y Leviathan, M Kalman, Y Matias, "Fast Inference from Transformers via Speculative Decoding", ICML 2023.</p>
<h2 id="pre-training-objective-of-llms">Pre-training Objective of LLMs</h2>
<p>A large language model trained from scratch is optimized using maximum likelihood estimation (MLE) over a large text corpus.</p>
<p>Given a sequence of tokens <span class="arithmatex">\((t_1, t_2, \ldots, t_n)\)</span> sampled from the data distribution <span class="arithmatex">\(p_\text{data}\)</span> the model defines an autoregressive factorization:</p>
<div class="arithmatex">\[
p_\theta(t_1, t_2, \ldots, t_n) = \prod_{i=1}^n p_\theta(t_i | t_1, t_2, \ldots, t_{i-1})
\]</div>
<p>The training objective is to maximize the log-likelihood of the data, which is equivalent to minimizing the negative log-likelihood (NLL):</p>
<div class="arithmatex">\[
\mathcal{L}(\theta) = - \mathbb{E}_{(t_1, t_2, \ldots, t_i) \sim p_\text{data}} \left[ \log p_\theta(t_i | t_1, t_2, \ldots, t_{i-1}) \right]
\]</div>
<p>In practice, this loss is implemented as token-level cross-entropy with one-hot targets:</p>
<div class="arithmatex">\[
\mathcal{L} = -\frac{1}{N} \sum_{\text{tokens}} \log p_\theta(t_i | t_1, t_2, \ldots, t_{i-1})
\]</div>
<p>This objective corresponds to minimizing the cross-entropy between the empirical data distribution and the model distribution. or equivalently, minimizing <span class="arithmatex">\(KL(p_\text{data} || p_\theta)\)</span>.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>