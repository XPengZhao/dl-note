{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"gpu/","title":"GPU Configuration","text":""},{"location":"gpu/#specific-gpus-explicitly","title":"Specific GPUs Explicitly","text":"<pre><code>torch.cuda.set_device(0,1)\n\n## or you can set the env variable\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n</code></pre> <p>or set the env variable when running the code:</p> <pre><code>CUDA_VISIBLE_DEVICES=0,1 python script.py\n</code></pre> <p>Comparison:</p> <p>If you want to restrict which GPUs are available to your script before it even starts, <code>CUDA_VISIBLE_DEVICES</code> is the way to go.</p> <p>If you want to change the active GPU dynamically based on some logic in your code, you'll need to use <code>torch.cuda.set_device()</code>.</p>"},{"location":"neural-graphics/","title":"Neural Graphics","text":""},{"location":"neural-graphics/#neural-radiance-fields-nerf","title":"Neural Radiance Fields (NeRF)","text":"<p>Neural Radiance Fields (NeRF) represents a scene as a continuous volumetric field, where the density \\(\\sigma \\in \\mathbb{R}\\) and radiance \\(\\mathbf{c} \\in \\mathbb{R}^3\\) at any 3D position \\(\\mathbf{x} \\in \\mathbb{R}^3\\) under viewing direction \\(\\mathbf{d} \\in \\mathbb{R}^3\\) are modeled by a multi-layer perceptron (MLP) \\(f_\\theta : (\\mathbf{x}, \\mathbf{d}) \\rightarrow (c, \\sigma)\\), with \\(\\theta\\) as learnable parameters. To render a pixel, the MLP first evaluates points sampled from the camera ray \\(\\mathbf{r} = \\mathbf{o} + t\\mathbf{d}\\) to get their densities and radiance, and then the color \\(\\mathbf{C}(\\mathbf{r})\\) is estimated by volume rendering equation approximated using quadrature:</p> \\[ \\widehat{\\mathbf{C}}(\\mathbf{r} ; \\sigma, \\mathbf{c})=\\sum_k T_i(\\sigma)\\left(1-\\exp \\left(-\\sigma_i \\delta_i\\right)\\right) \\mathbf{c}_i \\] <p>where \\(\\delta_i = t_{i+1} \u2212 t_i\\) and \\(T_i(\\sigma)=\\exp \\left(-\\sum_{j&lt;i} \\sigma_j \\delta_j\\right)\\). \\(\\widehat{\\mathbf{C}}\\) conditioned on \\(\\sigma\\), \\(\\mathbf{c}\\), and \\(T\\) is conditioned on \\(\\sigma\\) to simplify follow-up descriptions. We denote the contribution of a point to the cumulative color as its weight \\(\\omega_i\\):</p> \\[ \\omega_i=T_i(\\sigma)\\left(1-\\exp \\left(-\\sigma_i \\delta_i\\right)\\right) \\] <p>NeRF is optimized by minimizing the photometric loss:</p> \\[ \\mathcal{L}_{p m}=\\|\\widehat{\\mathbf{C}}-\\mathbf{C}\\|_2 \\]"},{"location":"neural-graphics/#physical-meanings-of-the-terms-in-the-volume-rendering-equation","title":"Physical meanings of the terms in the volume rendering equation","text":"<p>Alpha value of a point: \\(\\alpha_i = 1-\\exp \\left(-\\sigma_i \\delta_i\\right)\\)</p> <p>Contribution of a point to the cumulative color: \\(\\omega_i = T_i \\alpha_i\\)</p> <p>Opacity of each ray: \\(\\tau = \\sum_i \\omega_i\\)</p> <p>Depth of each ray: \\(d = \\sum_i \\omega_i t_i\\), where \\(t_i\\) is the distance between the i-th point and the camera</p>"},{"location":"tensor/","title":"Tensor Operations","text":""},{"location":"tensor/#tensor-creation","title":"Tensor Creation","text":""},{"location":"tensor/#dimension-operations","title":"Dimension Operations","text":""},{"location":"tensor/#add-a-new-dimension","title":"Add a new dimension","text":"<pre><code>t = torch.rand((3,4))  ## shaped [3, 4]\n\nt_new = t.unsqueeze(0) ## shaped [1, 3, 4]\nt_new = t.unsqueeze(1) ## shaped [3, 1, 4]\nt_new = t.unsqueeze(2) ## shaped [3, 4, 1]\n</code></pre>"},{"location":"tensor/#activate-function","title":"Activate Function","text":""},{"location":"tensor/#sigmoid","title":"Sigmoid","text":"<p>torch.sigmoid</p> <p>Computes the logistic sigmoid function of the elements of input.</p> \\[ \\text{out}_i = \\frac{1}{1 + e^{-\\text{input}_i}} \\] <pre><code>t = torch.randn(4)\ntorch.sigmoid(t)\n</code></pre> <p>```</p>"}]}